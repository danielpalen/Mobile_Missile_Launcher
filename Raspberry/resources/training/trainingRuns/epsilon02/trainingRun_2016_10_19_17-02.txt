
#########################################################
Episode 1

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:           0           0           0           0           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -11]

choosing greedy
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -31]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 2

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -4]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -11]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -15]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -18]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -19]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state  badPosition] [t_reward -21]

choosing greedy
 [state  badPosition] [action     left] [reward  -1] [n_ state        toFar] [t_reward -22]

choosing greedy
 [state        toFar] [action     left] [reward  -3] [n_ state  badPosition] [t_reward -25]

choosing greedy
 [state  badPosition] [action    right] [reward  -1] [n_ state        toFar] [t_reward -26]

choosing greedy
 [state        toFar] [action    right] [reward  -3] [n_ state  badPosition] [t_reward -29]

choosing greedy
-159.747 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -26]

choosing greedy
-17.457 pixels to the left
 [state        toFar] [action   toward] [reward  -1] [n_ state        toFar] [t_reward -27]

choosing greedy
 [state        toFar] [action     fire] [reward  -1] [n_ state        toFar] [t_reward -28]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573        -0.5          -2     -0.5438      -0.382   -0.417742
  badPosition:        -0.1        -0.1         0.3           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 3

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573        -0.5          -2     -0.5438      -0.382   -0.417742
  badPosition:        -0.1        -0.1         0.3           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward  -9]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -12]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -14]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -17]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -20]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -21]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -22]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -23]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -25]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -27]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -28]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -29]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -30]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -0.82143    -0.82143      -0.955          -2   -0.832321   -0.835484   -0.814398
  badPosition:        -0.1        -0.1         0.3           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 4

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -0.82143    -0.82143      -0.955          -2   -0.832321   -0.835484   -0.814398
  badPosition:        -0.1        -0.1         0.3           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -4]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -15]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -16]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -17]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -22]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -24]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -25]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -27]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -28]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -29]

choosing greedy
159.335 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -26]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward -23]

choosing greedy
70.1378 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -20]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward -17]

choosing greedy
 [state goodPosition] [action     left] [reward  -3] [n_ state  badPosition] [t_reward -20]

choosing greedy
336.338 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward -17]

choosing greedy
 [state goodPosition] [action    right] [reward  -3] [n_ state  badPosition] [t_reward -20]

choosing greedy
-241.58 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward -17]

choosing greedy
62.8528 pixels to the right
 [state goodPosition] [action   toward] [reward  -1] [n_ state goodPosition] [t_reward -18]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  -8]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.36905          -2    -1.07125    -1.07386   -0.982725
  badPosition:        -0.1        -0.1     1.23101           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     0.57513           0           0
 goodPosition:   -0.291839   -0.289656        -0.1           1           0           0           0

#########################################################
Episode 5

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.36905          -2    -1.07125    -1.07386   -0.982725
  badPosition:        -0.1        -0.1     1.23101           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     0.57513           0           0
 goodPosition:   -0.291839   -0.289656        -0.1           1           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing random
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -25]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.36905    -3.81031    -1.07125    -1.07386    -1.03099
  badPosition:        -0.1        -0.1     1.23101           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     0.57513           0           0
 goodPosition:   -0.291839   -0.289656        -0.1           1           0           0           0

#########################################################
Episode 6

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.36905    -3.81031    -1.07125    -1.07386    -1.03099
  badPosition:        -0.1        -0.1     1.23101           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     0.57513           0           0
 goodPosition:   -0.291839   -0.289656        -0.1           1           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -16]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward -17]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward -14]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward -11]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  -1]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.17484    -1.07386    -1.06034
  badPosition:        -0.1        -0.1     1.23101           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     1.05103           0           0
 goodPosition:   -0.291839   -0.289656        -0.1        1.91           0           0           0

#########################################################
Episode 7

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.17484    -1.07386    -1.06034
  badPosition:        -0.1        -0.1     1.23101           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     1.05103           0           0
 goodPosition:   -0.291839   -0.289656        -0.1        1.91           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -6]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -13]

choosing greedy
126.315 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -10]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -4]

choosing greedy
120.18 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  -1]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   9]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.26823    -1.17721     -1.0662
  badPosition:        -0.1        -0.1     1.59568           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     1.44498           0           0
 goodPosition:   -0.291839   -0.289656        -0.1      2.7381           0           0           0


 #########################################################
 Episode 8

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.26823    -1.17721     -1.0662
   badPosition:        -0.1        -0.1     1.59568           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     1.44498           0           0
  goodPosition:   -0.291839   -0.289656        -0.1      2.7381           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -4]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -1]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   5]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   8]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  18]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.26823    -1.17721    -1.05509
   badPosition:        -0.1        -0.1     1.59568           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     2.04667           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     3.49167           0           0           0

 #########################################################
 Episode 9

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.26823    -1.17721    -1.05509
   badPosition:        -0.1        -0.1     1.59568           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     2.04667           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     3.49167           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -10]

 choosing greedy
 -116.963 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -7]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -4]

 choosing greedy
 -82.6252 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -1]

 choosing greedy
 -51.811 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   2]

 choosing greedy
 -45.6616 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   5]

 choosing greedy
 -41.7069 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   8]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  11]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  21]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.26823    -1.17721    -1.06247
   badPosition:        -0.1        -0.1     2.25222           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     2.27853           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     4.17742           0           0           0

 #########################################################
 Episode 10

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.26823    -1.17721    -1.06247
   badPosition:        -0.1        -0.1     2.25222           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     2.27853           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     4.17742           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

 choosing greedy
 -130.365 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -6]

 choosing greedy
 -66.5473 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

 choosing greedy
 -76.601 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -1]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   2]

 choosing greedy
 -76.0763 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   5]

 choosing greedy
 -47.6075 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   8]

 choosing greedy
 -40.7085 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  11]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  14]

 choosing greedy
 -52.4875 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  17]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  27]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.26823    -1.17721    -1.02716
   badPosition:        -0.1        -0.1     2.76505           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     2.46491           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     4.80145           0           0           0

 #########################################################
 Episode 11

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.26823    -1.17721    -1.02716
   badPosition:        -0.1        -0.1     2.76505           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     2.46491           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     4.80145           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

 choosing greedy
 -113.464 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -7]

 choosing greedy
 -107.922 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -4]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -1]

 choosing greedy
 -90.6005 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   2]

 choosing greedy
 -51.51 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   5]

 choosing greedy
 -43.7045 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   8]

 choosing greedy
 -38.3709 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  11]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  14]

 choosing greedy
 -49.4474 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  17]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  27]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.26823    -1.17721    -1.00536
   badPosition:        -0.1        -0.1     3.03066           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     2.62181           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     5.36932           0           0           0

 #########################################################
 Episode 12

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.26823    -1.17721    -1.00536
   badPosition:        -0.1        -0.1     3.03066           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     2.62181           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     5.36932           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing random
  [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -6]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -3]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   0]

 choosing greedy
 -80.5322 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   3]

 choosing greedy
 -48.1439 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   6]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   9]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  19]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.35156    -1.17721    -1.00206
   badPosition:        -0.1        -0.1     3.07959           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     2.82651           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     5.88608           0           0           0

 #########################################################
 Episode 13

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.35156    -1.17721    -1.00206
   badPosition:        -0.1        -0.1     3.07959           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     2.82651           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     5.88608           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

 choosing greedy
 -204.632 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -6]

 choosing greedy
 -87.5342 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

 choosing greedy
 -88.3933 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -1]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   5]

 choosing greedy
 -116.72 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   8]

 choosing greedy
 -53.8493 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  11]

 choosing greedy
 -46.2734 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  14]

 choosing greedy
 -41.0064 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  17]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state  badPosition] [t_reward  27]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.35156    -1.17721   -0.989926
   badPosition:        -0.1        -0.1     3.20198           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     2.91593           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     6.32949           0           0           0

 #########################################################
 Episode 14

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.35156    -1.17721   -0.989926
   badPosition:        -0.1        -0.1     3.20198           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     2.91593           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     6.32949           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing random
  [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -6]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -3]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   0]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   3]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  13]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721   -0.988651
   badPosition:        -0.1        -0.1     3.20198           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.05221           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     6.75984           0           0           0

 #########################################################
 Episode 15

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721   -0.988651
   badPosition:        -0.1        -0.1     3.20198           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.05221           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     6.75984           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -9]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -6]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -3]

 choosing greedy
 -87.7304 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   0]

 choosing greedy
 -49.7163 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   3]

 choosing greedy
 -44.4499 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   6]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   9]

 choosing greedy
 -68.6435 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  12]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  22]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721    -1.01765
   badPosition:        -0.1        -0.1     3.27741           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.12393           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     7.15145           0           0           0

 #########################################################
 Episode 16

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721    -1.01765
   badPosition:        -0.1        -0.1     3.27741           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.12393           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     7.15145           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

 choosing greedy
 -205.808 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -6]

 choosing greedy
 -88.5599 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

 choosing greedy
 -84.9751 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -1]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   2]

 choosing greedy
 -83.9009 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   5]

 choosing greedy
 -53.6394 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   8]

 choosing greedy
 -45.8076 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  11]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  14]

 choosing greedy
 -53.1372 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  17]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  27]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721   -0.992464
   badPosition:        -0.1        -0.1     3.31443           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.16234           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     7.50782           0           0           0

 #########################################################
 Episode 17

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721   -0.992464
   badPosition:        -0.1        -0.1     3.31443           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.16234           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     7.50782           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -4]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -1]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   5]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   8]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  18]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721   -0.987908
   badPosition:        -0.1        -0.1     3.31443           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.25911           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     7.83212           0           0           0

 #########################################################
 Episode 18

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721   -0.987908
   badPosition:        -0.1        -0.1     3.31443           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.25911           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     7.83212           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -10]

 choosing greedy
 -194.23 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -7]

 choosing greedy
 -75.1214 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

 choosing greedy
 -289.366 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -6]

 choosing greedy
 -78.4722 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -3]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   0]

 choosing greedy
 -89.3778 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   3]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   6]

 choosing greedy
 -53.7069 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   9]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  19]


 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721    -1.01066
   badPosition:        -0.1        -0.1     3.35902           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.27256           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     8.12723           0           0           0

 #########################################################
 Episode 19

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721    -1.01066
   badPosition:        -0.1        -0.1     3.35902           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.27256           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     8.12723           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

 choosing greedy
 -99.8543 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -6]

 choosing greedy
 -66.6735 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -3]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   0]

 choosing greedy
 -79.8167 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   3]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   6]

 choosing greedy
 -82.5273 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   9]

 choosing greedy
 -50.1868 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  12]

 choosing greedy
 -42.7048 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  15]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  18]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  28]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721     -1.0239
   badPosition:        -0.1        -0.1     3.34614           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.33729           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     8.39578           0           0           0

 #########################################################
 Episode 20

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721     -1.0239
   badPosition:        -0.1        -0.1     3.34614           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.33729           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     8.39578           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

 choosing greedy
 -181.945 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -6]

 choosing greedy
 -87.2877 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -3]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   0]

 choosing greedy
 -86.6138 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   3]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   6]

 choosing greedy
 -85.9633 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   9]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  19]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81031    -1.42641    -1.17721    -1.02963
   badPosition:        -0.1        -0.1     3.38927           0           0           0           0
         toFar:        -0.3        -0.3        -0.1        -0.1     3.33645           0           0
  goodPosition:   -0.291839   -0.289656        -0.1     8.64016           0           0           0
