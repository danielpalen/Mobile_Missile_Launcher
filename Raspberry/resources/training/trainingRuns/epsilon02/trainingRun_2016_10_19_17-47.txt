
#########################################################
Episode 1

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:           0           0           0           0           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -11]

choosing greedy
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -31]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 2

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -4]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state  badPosition] [t_reward  -9]

choosing greedy
 [state  badPosition] [action     left] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -12]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -15]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -18]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -21]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -22]

choosing greedy
 [state  badPosition] [action    right] [reward  -1] [n_ state  badPosition] [t_reward -23]

choosing greedy
-213.594 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -20]

choosing greedy
 [state        toFar] [action     left] [reward  -3] [n_ state  badPosition] [t_reward -23]

choosing greedy
137.564 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -20]

choosing random
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward -17]

choosing greedy
62.3928 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -14]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward -11]

choosing greedy
 [state goodPosition] [action     left] [reward  -3] [n_ state  badPosition] [t_reward -14]

choosing greedy
258.005 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward -11]

choosing greedy
 [state goodPosition] [action    right] [reward  -3] [n_ state  badPosition] [t_reward -14]

choosing greedy
-154.144 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward -11]

choosing greedy
-16.6332 pixels to the left
 [state goodPosition] [action   toward] [reward  -1] [n_ state goodPosition] [t_reward -12]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  -2]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573        -0.5          -2      -0.545      -0.382    -0.41425
  badPosition:      -0.102        -0.1     1.23101           0           0           0           0
        toFar:      -0.297           0           0           0     0.57513           0           0
 goodPosition:   -0.291839   -0.289656        -0.1           1           0           0           0

#########################################################
Episode 3

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573        -0.5          -2      -0.545      -0.382    -0.41425
  badPosition:      -0.102        -0.1     1.23101           0           0           0           0
        toFar:      -0.297           0           0           0     0.57513           0           0
 goodPosition:   -0.291839   -0.289656        -0.1           1           0           0           0
choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward  -9]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -12]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -14]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -17]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -20]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -21]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -22]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -23]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -25]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -27]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -28]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -30]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -0.82143    -0.82143      -0.955          -2   -0.957493   -0.835484      -0.751
  badPosition:      -0.102        -0.1     1.23101           0           0           0           0
        toFar:      -0.297           0           0           0     0.57513           0           0
 goodPosition:   -0.291839   -0.289656        -0.1           1           0           0           0

#########################################################
Episode 4

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -0.82143    -0.82143      -0.955          -2   -0.957493   -0.835484      -0.751
  badPosition:      -0.102        -0.1     1.23101           0           0           0           0
        toFar:      -0.297           0           0           0     0.57513           0           0
 goodPosition:   -0.291839   -0.289656        -0.1           1           0           0           0
choosing random
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -8]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -11]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -15]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -16]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -17]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state        toFar] [t_reward -22]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward -19]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward -16]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward -13]

choosing greedy
-125.338 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward -10]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   0]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.35375          -2   -0.957493   -0.959446   -0.957009
  badPosition:      -0.102        -0.1     1.41791           0           0           0           0
        toFar:      -0.297           0           0           0     1.25665           0           0
 goodPosition:   -0.291839   -0.289656        -0.1        1.91           0           0           0

#########################################################
Episode 5

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.35375          -2   -0.957493   -0.959446   -0.957009
  badPosition:      -0.102        -0.1     1.41791           0           0           0           0
        toFar:      -0.297           0           0           0     1.25665           0           0
 goodPosition:   -0.291839   -0.289656        -0.1        1.91           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

choosing greedy
141.312 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -11]

choosing greedy
-137.593 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-88.2019 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   1]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  11]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.35375          -2    -1.07132     -1.0731    -1.01144
  badPosition:      -0.102        -0.1      1.8645           0           0           0           0
        toFar:      -0.297           0           0           0     1.62249           0           0
 goodPosition:   -0.291839   -0.289656        -0.1      2.7381           0           0           0

#########################################################
Episode 6

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.35375          -2    -1.07132     -1.0731    -1.01144
  badPosition:      -0.102        -0.1      1.8645           0           0           0           0
        toFar:      -0.297           0           0           0     1.62249           0           0
 goodPosition:   -0.291839   -0.289656        -0.1      2.7381           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -8]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -11]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -15]

choosing greedy
-105.12 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -12]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -9]

choosing greedy
-104.835 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
-97.401 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   0]

choosing greedy
-49.8042 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   6]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  16]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2    -1.07132     -1.0731    -1.03917
  badPosition:      -0.102        -0.1     2.31949           0           0           0           0
        toFar:      -0.297           0           0           0     2.05834           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     3.49167           0           0           0

#########################################################
Episode 7

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2    -1.07132     -1.0731    -1.03917
  badPosition:      -0.102        -0.1     2.31949           0           0           0           0
        toFar:      -0.297           0           0           0     2.05834           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     3.49167           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward -13]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward -10]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -4]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   6]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2     -1.1749    -1.17652    -1.04897
  badPosition:      -0.102        -0.1     2.31949           0           0           0           0
        toFar:      -0.297           0           0           0     2.38468           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     4.17742           0           0           0

#########################################################
Episode 8

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2     -1.1749    -1.17652    -1.04897
  badPosition:      -0.102        -0.1     2.31949           0           0           0           0
        toFar:      -0.297           0           0           0     2.38468           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     4.17742           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
77.2858 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -1]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -7]

choosing greedy
-146.647 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-102.236 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   2]

choosing greedy
-51.3629 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   8]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  18]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2     -1.1749    -1.17652    -1.03329
  badPosition:      -0.102        -0.1     2.61217           0           0           0           0
        toFar:      -0.297           0           0           0     2.56553           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     4.80145           0           0           0

#########################################################
Episode 9

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2     -1.1749    -1.17652    -1.03329
  badPosition:      -0.102        -0.1     2.61217           0           0           0           0
        toFar:      -0.297           0           0           0     2.56553           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     4.80145           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
111.488 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -1]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -7]

choosing greedy
-161.794 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-86.5534 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   5]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  15]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2     -1.1749    -1.17652    -1.02304
  badPosition:      -0.102        -0.1     2.75845           0           0           0           0
        toFar:      -0.297           0           0           0     2.72041           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     5.36932           0           0           0

#########################################################
Episode 10

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2     -1.1749    -1.17652    -1.02304
  badPosition:      -0.102        -0.1     2.75845           0           0           0           0
        toFar:      -0.297           0           0           0     2.72041           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     5.36932           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state  badPosition] [t_reward -11]

choosing greedy
-126.694 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-97.1322 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -2]

choosing greedy
-51.4376 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   1]

choosing greedy
-44.4936 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   7]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  17]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2    -1.22983    -1.17652    -1.07342
  badPosition:      -0.102        -0.1     2.93759           0           0           0           0
        toFar:      -0.297           0           0           0     2.85251           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     5.88608           0           0           0

#########################################################
Episode 11

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2    -1.22983    -1.17652    -1.07342
  badPosition:      -0.102        -0.1     2.93759           0           0           0           0
        toFar:      -0.297           0           0           0     2.85251           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     5.88608           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   0]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  10]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2    -1.22983    -1.17652    -1.05552
  badPosition:      -0.102        -0.1     2.93759           0           0           0           0
        toFar:      -0.297           0           0           0     3.00051           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     6.35633           0           0           0

#########################################################
Episode 12

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2    -1.22983    -1.17652    -1.05552
  badPosition:      -0.102        -0.1     2.93759           0           0           0           0
        toFar:      -0.297           0           0           0     3.00051           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     6.35633           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

choosing greedy
-77.6824 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -7]

choosing greedy
-93.0949 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-86.5115 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   5]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  15]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2    -1.22983    -1.17652    -1.01305
  badPosition:      -0.102        -0.1     3.00333           0           0           0           0
        toFar:      -0.297           0           0           0     3.09071           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     6.78426           0           0           0

#########################################################
Episode 13

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2    -1.22983    -1.17652    -1.01305
  badPosition:      -0.102        -0.1     3.00333           0           0           0           0
        toFar:      -0.297           0           0           0     3.09071           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     6.78426           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
-94.1119 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   0]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   3]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  13]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2    -1.22983    -1.17652    -1.02759
  badPosition:      -0.102        -0.1     3.03431           0           0           0           0
        toFar:      -0.297           0           0           0     3.18603           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     7.17368           0           0           0

#########################################################
Episode 14

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2    -1.22983    -1.17652    -1.02759
  badPosition:      -0.102        -0.1     3.03431           0           0           0           0
        toFar:      -0.297           0           0           0     3.18603           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     7.17368           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

choosing greedy
-92.7183 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -6]

choosing random
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -7]

choosing random
-97.7297 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-84.7866 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   2]

choosing greedy
-48.5767 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   8]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  18]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2    -1.22983    -1.17652    -1.00067
  badPosition:      -0.102        -0.1     3.10021           0           0           0           0
        toFar:      -0.297           0           0           0     3.24987           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     7.52805           0           0           0

#########################################################
Episode 15

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375          -2    -1.22983    -1.17652    -1.00067
  badPosition:      -0.102        -0.1     3.10021           0           0           0           0
        toFar:      -0.297           0           0           0     3.24987           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     7.52805           0           0           0
choosing random
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing random
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -28]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375    -3.81048    -1.22983    -1.26887    -1.04839
  badPosition:      -0.102        -0.1     3.10021           0           0           0           0
        toFar:      -0.297           0           0           0     3.24987           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     7.52805           0           0           0

#########################################################
Episode 16

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375    -3.81048    -1.22983    -1.26887    -1.04839
  badPosition:      -0.102        -0.1     3.10021           0           0           0           0
        toFar:      -0.297           0           0           0     3.24987           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     7.52805           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

choosing greedy
-108.93 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
-94.3165 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   0]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   3]

choosing greedy
-83.3302 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   9]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  19]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375    -3.81048    -1.22983    -1.26887    -1.04245
  badPosition:      -0.102        -0.1      3.1613           0           0           0           0
        toFar:      -0.297           0           0           0     3.31102           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     7.85053           0           0           0

#########################################################
Episode 17

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375    -3.81048    -1.22983    -1.26887    -1.04245
  badPosition:      -0.102        -0.1      3.1613           0           0           0           0
        toFar:      -0.297           0           0           0     3.31102           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     7.85053           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -10]

choosing greedy
-205.125 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -4]

choosing greedy
-102.041 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-52.514 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   2]

choosing greedy
-44.5457 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   5]

choosing greedy
-40.5442 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  11]

choosing greedy
-70.0532 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  14]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  24]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375    -3.81048    -1.22983    -1.26887    -1.04194
  badPosition:      -0.102        -0.1     3.28367           0           0           0           0
        toFar:      -0.297           0           0           0     3.31281           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     8.14398           0           0           0

#########################################################
Episode 18

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375    -3.81048    -1.22983    -1.26887    -1.04194
  badPosition:      -0.102        -0.1     3.28367           0           0           0           0
        toFar:      -0.297           0           0           0     3.31281           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     8.14398           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

choosing greedy
-77.267 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
-90.6253 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   0]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   3]

choosing greedy
-89.2059 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   6]

choosing greedy
-50.9164 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  12]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  22]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375    -3.81048    -1.22983    -1.26887    -1.03789
  badPosition:      -0.102        -0.1     3.29991           0           0           0           0
        toFar:      -0.297           0           0           0     3.36575           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     8.41102           0           0           0

#########################################################
Episode 19

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375    -3.81048    -1.22983    -1.26887    -1.03789
  badPosition:      -0.102        -0.1     3.29991           0           0           0           0
        toFar:      -0.297           0           0           0     3.36575           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     8.41102           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -10]

choosing greedy
-176.349 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -4]

choosing random
-98.9605 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-48.6677 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   2]

choosing greedy
-41.3547 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   8]

choosing greedy
-77.0284 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  11]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  21]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375    -3.81048    -1.22983    -1.26887     -1.0388
  badPosition:      -0.102        -0.1     3.36441           0           0           0           0
        toFar:      -0.297           0           0           0      3.3591           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     8.65403           0           0           0

#########################################################
Episode 20

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375    -3.81048    -1.22983    -1.26887     -1.0388
  badPosition:      -0.102        -0.1     3.36441           0           0           0           0
        toFar:      -0.297           0           0           0      3.3591           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     8.65403           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
82.8141 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -1]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state        toFar] [t_reward  -3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   0]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   3]

choosing greedy
121.367 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   6]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  16]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.35375    -3.81048    -1.27326    -1.26887    -1.01731
  badPosition:      -0.102        -0.1     3.37256           0           0           0           0
        toFar:      -0.297           0           0           0     3.35428           0           0
 goodPosition:   -0.291839   -0.289656        -0.1     8.87517           0           0           0
