
#########################################################
Episode 1

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:           0           0           0           0           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -11]

choosing greedy
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -31]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 2

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -4]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state  badPosition] [t_reward  -9]

choosing greedy
 [state  badPosition] [action     left] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -12]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -16]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -19]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -20]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state  badPosition] [t_reward -22]

choosing greedy
 [state  badPosition] [action    right] [reward  -1] [n_ state     noTarget] [t_reward -23]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -25]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -26]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -27]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -32]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573      -0.955          -2      -0.542    -0.54762   -0.536932
  badPosition:      -0.102    -0.10382           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 3

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573      -0.955          -2      -0.542    -0.54762   -0.536932
  badPosition:      -0.102    -0.10382           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -5]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -8]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -14]

choosing greedy
98.7476 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward -11]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state        toFar] [t_reward -13]

choosing greedy
 [state        toFar] [action     left] [reward  -3] [n_ state  badPosition] [t_reward -16]

choosing greedy
225.16 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -13]

choosing greedy
 [state        toFar] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -16]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -18]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -19]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -20]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -21]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -22]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -25]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -28]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -30]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475      -0.955          -2   -0.949747   -0.835484    -0.83645
  badPosition:      -0.102    -0.10382    0.563761           0           0           0           0
        toFar:   -0.297069   -0.306983           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 4

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475      -0.955          -2   -0.949747   -0.835484    -0.83645
  badPosition:      -0.102    -0.10382    0.563761           0           0           0           0
        toFar:   -0.297069   -0.306983           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -10]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -15]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -16]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -18]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -19]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -20]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -21]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -22]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -23]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -24]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -25]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -26]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -27]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -30]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322     -1.0475    -1.36905          -2    -1.06427    -1.07386    -1.05037
  badPosition:      -0.102    -0.10382    0.563761           0           0           0           0
        toFar:   -0.297069   -0.306983           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 5

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322     -1.0475    -1.36905          -2    -1.06427    -1.07386    -1.05037
  badPosition:      -0.102    -0.10382    0.563761           0           0           0           0
        toFar:   -0.297069   -0.306983           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -8]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -13]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -15]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -17]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -18]

choosing greedy
-303.38 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -15]

choosing greedy
-61.399 pixels to the left
 [state        toFar] [action   toward] [reward  -1] [n_ state        toFar] [t_reward -16]

choosing greedy
 [state        toFar] [action     fire] [reward  -1] [n_ state        toFar] [t_reward -17]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246    -1.17721    -1.06866
  badPosition:      -0.102    -0.10382    0.807385           0           0           0           0
        toFar:   -0.297069   -0.306983        -0.1        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 6

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246    -1.17721    -1.06866
  badPosition:      -0.102    -0.10382    0.807385           0           0           0           0
        toFar:   -0.297069   -0.306983        -0.1        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

choosing greedy
-76.2635 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
-89.8384 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   0]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   3]

choosing greedy
-83.5126 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   6]

choosing greedy
-46.2818 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  12]

choosing greedy
 [state goodPosition] [action     left] [reward  -3] [n_ state  badPosition] [t_reward   9]

choosing greedy
116.739 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  12]

choosing greedy
 [state goodPosition] [action    right] [reward  -3] [n_ state  badPosition] [t_reward   9]

choosing greedy
-101.496 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  12]

choosing greedy
-35.6909 pixels to the left
 [state goodPosition] [action   toward] [reward  -1] [n_ state goodPosition] [t_reward  11]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  21]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246    -1.17721    -1.07396
  badPosition:      -0.102    -0.10382     1.85053           0           0           0           0
        toFar:   -0.297069   -0.306983        -0.1        -0.1     0.83236           0           0
 goodPosition:   -0.284191   -0.282772        -0.1           1           0           0           0

#########################################################
Episode 7

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246    -1.17721    -1.07396
  badPosition:      -0.102    -0.10382     1.85053           0           0           0           0
        toFar:   -0.297069   -0.306983        -0.1        -0.1     0.83236           0           0
 goodPosition:   -0.284191   -0.282772        -0.1           1           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
69.3285 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   2]

choosing random
 [state        toFar] [action     left] [reward  -3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
207.838 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   8]

choosing greedy
103.888 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  11]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  21]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246    -1.17721     -1.0563
  badPosition:      -0.102    -0.10382      2.1883           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1     1.45692           0           0
 goodPosition:   -0.284191   -0.282772        -0.1        1.91           0           0           0

#########################################################
Episode 8

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246    -1.17721     -1.0563
  badPosition:      -0.102    -0.10382      2.1883           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1     1.45692           0           0
 goodPosition:   -0.284191   -0.282772        -0.1        1.91           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
145.599 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -1]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
-89.1323 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   0]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   3]

choosing greedy
-84.986 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   6]

choosing greedy
-46.4513 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  12]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  22]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246    -1.17721    -1.04212
  badPosition:      -0.102    -0.10382     2.51217           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1     1.93364           0           0
 goodPosition:   -0.284191   -0.282772        -0.1      2.7381           0           0           0

#########################################################
Episode 9

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246    -1.17721    -1.04212
  badPosition:      -0.102    -0.10382     2.51217           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1     1.93364           0           0
 goodPosition:   -0.284191   -0.282772        -0.1      2.7381           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -6]

choosing greedy
-83.1045 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   0]

choosing greedy
-80.5105 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   3]

choosing greedy
-48.2473 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   9]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  19]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246    -1.17721    -1.05146
  badPosition:      -0.102    -0.10382     2.70618           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1     2.29359           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     3.49167           0           0           0

#########################################################
Episode 10

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246    -1.17721    -1.05146
  badPosition:      -0.102    -0.10382     2.70618           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1     2.29359           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     3.49167           0           0           0
choosing random
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -12]

choosing greedy
-162.241 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -6]

choosing greedy
-105.683 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   0]

choosing greedy
-98.3013 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   6]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  16]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246       -1.27    -1.04996
  badPosition:      -0.102    -0.10382     2.85072           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1     2.56755           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     4.17742           0           0           0

#########################################################
Episode 11

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246       -1.27    -1.04996
  badPosition:      -0.102    -0.10382     2.85072           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1     2.56755           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     4.17742           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -6]

choosing greedy
-95.2142 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   0]

choosing greedy
-85.4867 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   3]

choosing greedy
-45.5967 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   9]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  19]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246       -1.27    -1.04844
  badPosition:      -0.102    -0.10382     2.96562           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1     2.77564           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     4.80145           0           0           0

#########################################################
Episode 12

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246       -1.27    -1.04844
  badPosition:      -0.102    -0.10382     2.96562           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1     2.77564           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     4.80145           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -10]

choosing greedy
-107.496 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -4]

choosing greedy
-87.2882 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-45.0092 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   5]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  15]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246       -1.27    -1.04621
  badPosition:      -0.102    -0.10382     3.05267           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1     2.89325           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     5.36932           0           0           0

#########################################################
Episode 13

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246       -1.27    -1.04621
  badPosition:      -0.102    -0.10382     3.05267           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1     2.89325           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     5.36932           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   0]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  10]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246       -1.27     -1.0436
  badPosition:      -0.102    -0.10382     3.05267           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1      3.0257           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     5.88608           0           0           0

#########################################################
Episode 14

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.26246       -1.27     -1.0436
  badPosition:      -0.102    -0.10382     3.05267           0           0           0           0
        toFar:   -0.547624   -0.306983        -0.1        -0.1      3.0257           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     5.88608           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
181.339 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -1]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing random
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

choosing random
f
 [state  badPosition] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -10]

choosing greedy
-219.191 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -7]

choosing random
-55.3664 pixels to the left
 [state        toFar] [action   toward] [reward  -1] [n_ state        toFar] [t_reward  -8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-73.2422 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   1]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  11]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.36905          -2    -1.26246       -1.27    -1.01567
  badPosition:      -0.102    -0.10382     3.08787           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.10725           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     6.35633           0           0           0

#########################################################
Episode 15

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.36905          -2    -1.26246       -1.27    -1.01567
  badPosition:      -0.102    -0.10382     3.08787           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.10725           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     6.35633           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
196.333 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
79.2995 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward   2]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   1]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   0]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-118.101 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   2]

choosing greedy
-55.5613 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   8]

choosing greedy
-84.3946 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  11]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  21]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.36905          -2    -1.26246       -1.27    -1.00899
  badPosition:      -0.102    -0.10382     3.18155           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.14598           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     6.78426           0           0           0

#########################################################
Episode 16

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.36905          -2    -1.26246       -1.27    -1.00899
  badPosition:      -0.102    -0.10382     3.18155           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.14598           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     6.78426           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing random
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
137.451 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -1]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -7]

choosing greedy
-73.6921 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-92.5574 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   2]

choosing greedy
-49.7053 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   8]

choosing greedy
-79.2647 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  11]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  21]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.36905          -2    -1.26246       -1.27    -1.00546
  badPosition:      -0.102    -0.10382     3.24557           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.17874           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     7.17368           0           0           0

#########################################################
Episode 17

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.36905          -2    -1.26246       -1.27    -1.00546
  badPosition:      -0.102    -0.10382     3.24557           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.17874           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     7.17368           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

choosing greedy
71.7183 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   0]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   3]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  13]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.36905          -2    -1.26246       -1.27    -1.02283
  badPosition:      -0.102    -0.10382      3.2528           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.25652           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     7.52805           0           0           0

#########################################################
Episode 18

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.36905          -2    -1.26246       -1.27    -1.02283
  badPosition:      -0.102    -0.10382      3.2528           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.25652           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     7.52805           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing random
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -13]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward -14]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward -11]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -5]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   5]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.74284          -2    -1.26246       -1.27    -1.03007
  badPosition:      -0.102    -0.10382      3.2528           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.31803           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     7.85053           0           0           0

#########################################################
Episode 19

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.74284          -2    -1.26246       -1.27    -1.03007
  badPosition:      -0.102    -0.10382      3.2528           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.31803           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     7.85053           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
113.255 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
65.0319 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state     noTarget] [t_reward   5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   3]

choosing random
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward   1]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   0]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.74284          -2    -1.26246    -1.35329    -1.00638
  badPosition:      -0.102    -0.10382     3.26722           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.33163           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     8.14398           0           0           0

#########################################################
Episode 20

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.74284          -2    -1.26246    -1.35329    -1.00638
  badPosition:      -0.102    -0.10382     3.26722           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.33163           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     8.14398           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
-62.1798 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   0]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   3]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  13]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.43841    -1.74284          -2    -1.26246    -1.35329    -1.02236
  badPosition:      -0.102    -0.10382     3.27381           0           0           0  -0.0696283
        toFar:   -0.547624   -0.306983   -0.159743        -0.1     3.37959           0           0
 goodPosition:   -0.284191   -0.282772        -0.1     8.41102           0           0           0
