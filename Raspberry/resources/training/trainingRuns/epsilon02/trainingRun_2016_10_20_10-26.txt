
#########################################################
Episode 1

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:           0           0           0           0           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -11]

choosing greedy
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -31]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 2

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -4]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -11]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -14]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -17]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -20]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -21]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -23]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -24]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -25]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -30]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573      -0.955          -2     -0.5468    -0.54762   -0.536932
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 3

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573      -0.955          -2     -0.5468    -0.54762   -0.536932
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -5]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -8]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -16]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -18]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -19]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -20]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -21]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -22]

choosing greedy
 [state  badPosition] [action     left] [reward  -1] [n_ state        toFar] [t_reward -23]

choosing greedy
 [state        toFar] [action     left] [reward  -3] [n_ state  badPosition] [t_reward -26]

choosing greedy
 [state  badPosition] [action    right] [reward  -1] [n_ state        toFar] [t_reward -27]

choosing greedy
 [state        toFar] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -30]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -0.82143    -0.82143      -0.955          -2   -0.834805   -0.835484   -0.832958
  badPosition:        -0.1        -0.1           0           0           0           0           0
        toFar:        -0.3   -0.308214           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 4

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -0.82143    -0.82143      -0.955          -2   -0.834805   -0.835484   -0.832958
  badPosition:        -0.1        -0.1           0           0           0           0           0
        toFar:        -0.3   -0.308214           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -15]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -16]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -17]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -22]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -24]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -26]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -27]

choosing random
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -30]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255     -1.0475    -1.36905          -2     -1.0733    -1.07386   -0.980309
  badPosition:        -0.1        -0.1           0           0           0           0           0
        toFar:        -0.3   -0.308214           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 5

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255     -1.0475    -1.36905          -2     -1.0733    -1.07386   -0.980309
  badPosition:        -0.1        -0.1           0           0           0           0           0
        toFar:        -0.3   -0.308214           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -3]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -7]

choosing greedy
-246.188 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
25.3143 pixels to the right
 [state        toFar] [action   toward] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

choosing greedy
-168.064 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action     fire] [reward  -1] [n_ state        toFar] [t_reward  -6]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255     -1.0475    -1.36905          -2    -1.17589    -1.07386    -1.02855
  badPosition:        -0.1        -0.1        0.57           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 6

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255     -1.0475    -1.36905          -2    -1.17589    -1.07386    -1.02855
  badPosition:        -0.1        -0.1        0.57           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -7]

choosing greedy
91.7378 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   2]

choosing greedy
100.565 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   5]

choosing greedy
48.5125 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  11]

choosing greedy
 [state goodPosition] [action     left] [reward  -3] [n_ state  badPosition] [t_reward   8]

choosing greedy
262.569 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  11]

choosing greedy
 [state goodPosition] [action    right] [reward  -3] [n_ state  badPosition] [t_reward   8]

choosing random
 [state  badPosition] [action     left] [reward  -1] [n_ state goodPosition] [t_reward   7]

choosing greedy
31.2001 pixels to the right
 [state goodPosition] [action   toward] [reward  -1] [n_ state goodPosition] [t_reward   6]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  16]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.07386    -1.03831
  badPosition:       -0.19        -0.1     1.41747           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1    0.820317           0           0
 goodPosition:   -0.287584   -0.285825        -0.1           1           0           0           0

#########################################################
Episode 7

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.07386    -1.03831
  badPosition:       -0.19        -0.1     1.41747           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1    0.820317           0           0
 goodPosition:   -0.287584   -0.285825        -0.1           1           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -10]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -11]

choosing greedy
83.306 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -8]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
124.689 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   0]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   3]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  13]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.17721    -1.04131
  badPosition:       -0.19        -0.1     1.72123           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     1.44174           0           0
 goodPosition:   -0.287584   -0.285825        -0.1        1.91           0           0           0

#########################################################
Episode 8

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.17721    -1.04131
  badPosition:       -0.19        -0.1     1.72123           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     1.44174           0           0
 goodPosition:   -0.287584   -0.285825        -0.1        1.91           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
164.389 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   2]

choosing greedy
84.5567 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  11]

choosing greedy
109.909 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  14]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  24]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.17721    -1.03545
  badPosition:       -0.19        -0.1      2.1131           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1      1.9136           0           0
 goodPosition:   -0.287584   -0.285825        -0.1      2.7381           0           0           0

#########################################################
Episode 9

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.17721    -1.03545
  badPosition:       -0.19        -0.1      2.1131           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1      1.9136           0           0
 goodPosition:   -0.287584   -0.285825        -0.1      2.7381           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
212.156 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -1]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -6]

choosing greedy
-125.75 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   0]

choosing greedy
-77.6314 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   6]

choosing greedy
-77.6118 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   9]

choosing greedy
-41.8878 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  12]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  15]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  25]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.17721    -1.02652
  badPosition:       -0.19        -0.1     2.54316           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1      2.2754           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     3.49167           0           0           0

#########################################################
Episode 10

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.17721    -1.02652
  badPosition:       -0.19        -0.1     2.54316           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1      2.2754           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     3.49167           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward -10]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -4]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   6]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.17721    -1.04467
  badPosition:       -0.19        -0.1     2.54316           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     2.46847           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     4.17742           0           0           0

#########################################################
Episode 11

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.17721    -1.04467
  badPosition:       -0.19        -0.1     2.54316           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     2.46847           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     4.17742           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
187.893 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -1]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -7]

choosing greedy
-136.706 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-71.7907 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   5]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  15]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.17721    -1.02838
  badPosition:       -0.19        -0.1     2.70632           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     2.63504           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     4.80145           0           0           0

#########################################################
Episode 12

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.17721    -1.02838
  badPosition:       -0.19        -0.1     2.70632           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     2.63504           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     4.80145           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -10]

choosing greedy
144.497 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -4]

choosing greedy
78.1778 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   2]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  12]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.17721    -1.04107
  badPosition:       -0.19        -0.1     2.81283           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     2.77726           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     5.36932           0           0           0

#########################################################
Episode 13

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25255    -1.25322    -1.36905          -2    -1.17589    -1.17721    -1.04107
  badPosition:       -0.19        -0.1     2.81283           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     2.77726           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     5.36932           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing random
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -11]

choosing greedy
-207.577 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-107.098 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   1]

choosing greedy
-73.1514 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   7]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  17]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905          -2    -1.17589    -1.17721     -1.0393
  badPosition:       -0.19        -0.1     2.94025           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     2.94059           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     5.88608           0           0           0

#########################################################
Episode 14

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905          -2    -1.17589    -1.17721     -1.0393
  badPosition:       -0.19        -0.1     2.94025           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     2.94059           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     5.88608           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing random
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -13]

choosing greedy
-238.448 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -10]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -1]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   9]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905          -2    -1.17589    -1.27015    -1.04543
  badPosition:       -0.19        -0.1     2.97563           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.06615           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     6.35633           0           0           0

#########################################################
Episode 15

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905          -2    -1.17589    -1.27015    -1.04543
  badPosition:       -0.19        -0.1     2.97563           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.06615           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     6.35633           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   0]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  10]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905          -2    -1.17589    -1.27015    -1.04154
  badPosition:       -0.19        -0.1     2.97563           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.16443           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     6.78426           0           0           0

#########################################################
Episode 16

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905          -2    -1.17589    -1.27015    -1.04154
  badPosition:       -0.19        -0.1     2.97563           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.16443           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     6.78426           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
65.8506 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   0]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   3]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  13]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905          -2    -1.17589    -1.27015    -1.03891
  badPosition:       -0.19        -0.1     3.00998           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.24012           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     7.17368           0           0           0

#########################################################
Episode 17

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905          -2    -1.17589    -1.27015    -1.03891
  badPosition:       -0.19        -0.1     3.00998           0           0           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.24012           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     7.17368           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing random
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -5]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -12]

choosing random
 [state  badPosition] [action  forward] [reward   0] [n_ state  badPosition] [t_reward -12]

choosing greedy
266.528 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
137.731 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   0]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  10]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905          -2    -1.17589     -1.3537    -1.04209
  badPosition:       -0.19        -0.1     3.10898           0   0.0300998           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.25407           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     7.52805           0           0           0

#########################################################
Episode 18

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905          -2    -1.17589     -1.3537    -1.04209
  badPosition:       -0.19        -0.1     3.10898           0   0.0300998           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.25407           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     7.52805           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
150.777 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
65.5445 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward   2]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   1]

choosing random
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -19]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905     -3.8103    -1.17589     -1.3537    -1.03011
  badPosition:       -0.19        -0.1     3.10603           0   0.0300998           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.25407           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     7.52805           0           0           0

#########################################################
Episode 19

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905     -3.8103    -1.17589     -1.3537    -1.03011
  badPosition:       -0.19        -0.1     3.10603           0   0.0300998           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.25407           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     7.52805           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
215.155 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   2]

choosing greedy
76.9265 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  11]

choosing greedy
98.6831 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  14]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  24]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905     -3.8103    -1.17589     -1.3537      -1.014
  badPosition:       -0.19        -0.1     3.20827           0   0.0300998           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.27137           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     7.85053           0           0           0

#########################################################
Episode 20

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905     -3.8103    -1.17589     -1.3537      -1.014
  badPosition:       -0.19        -0.1     3.20827           0   0.0300998           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.27137           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     7.85053           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -4]

choosing greedy
222.891 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -1]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -6]

choosing greedy
-98.3576 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   0]

choosing greedy
-85.3916 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   6]

choosing greedy
-73.0107 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  12]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  22]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.43793    -1.25322    -1.36905     -3.8103    -1.17589     -1.3537    -1.00092
  badPosition:       -0.19        -0.1     3.21813           0   0.0300998           0           0
        toFar:        -0.3   -0.308214   -0.110193        -0.1     3.33105           0           0
 goodPosition:   -0.287584   -0.285825        -0.1     8.14398           0           0           0
