
#########################################################
Episode 1

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:           0           0           0           0           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -11]

choosing greedy
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -31]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 2

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -4]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state  badPosition] [t_reward  -9]

choosing greedy
 [state  badPosition] [action     left] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -12]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -16]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -19]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -20]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -22]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -24]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -25]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -26]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -31]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573      -0.955          -2     -0.5458    -0.54762   -0.536932
  badPosition:      -0.102           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 3

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573      -0.955          -2     -0.5458    -0.54762   -0.536932
  badPosition:      -0.102           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -5]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -8]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -16]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -18]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -19]

choosing greedy
 [state  badPosition] [action    right] [reward  -1] [n_ state  badPosition] [t_reward -20]

choosing greedy
-75.0206 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward -17]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -18]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -19]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -20]

choosing greedy
-175.454 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -17]

choosing greedy
 [state        toFar] [action     left] [reward  -3] [n_ state  badPosition] [t_reward -20]

choosing greedy
176.317 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -17]

choosing greedy
 [state        toFar] [action    right] [reward  -3] [n_ state  badPosition] [t_reward -20]

choosing greedy
-179.763 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -17]

choosing greedy
30.2078 pixels to the right
 [state        toFar] [action   toward] [reward  -1] [n_ state        toFar] [t_reward -18]

choosing greedy
 [state        toFar] [action     fire] [reward  -1] [n_ state     noTarget] [t_reward -19]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -0.82143    -0.82143      -0.955          -2   -0.833977   -0.835484   -0.824686
  badPosition:      -0.102        -0.1     1.02626           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.108214           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 4

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -0.82143    -0.82143      -0.955          -2   -0.833977   -0.835484   -0.824686
  badPosition:      -0.102        -0.1     1.02626           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.108214           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -15]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -16]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -17]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -22]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -24]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -26]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -27]

choosing greedy
-121.586 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -24]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward -21]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward -18]

choosing greedy
-105.097 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward -15]

choosing greedy
 [state goodPosition] [action     left] [reward  -3] [n_ state  badPosition] [t_reward -18]

choosing greedy
248.563 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward -15]

choosing greedy
-74.0812 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward -12]

choosing greedy
 [state goodPosition] [action    right] [reward  -3] [n_ state  badPosition] [t_reward -15]

choosing greedy
-269.978 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward -12]

choosing greedy
136.547 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  -9]

choosing greedy
-0.637482 pixels to the left
 [state goodPosition] [action   toward] [reward  -1] [n_ state goodPosition] [t_reward -10]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   0]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.36905          -2    -1.07262    -1.07386   -0.956525
  badPosition:      -0.102        -0.1     1.97675           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.108214    0.582236           0           0
 goodPosition:   -0.285987   -0.282824        -0.1           1           0           0           0

#########################################################
Episode 5

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.36905          -2    -1.07262    -1.07386   -0.956525
  badPosition:      -0.102        -0.1     1.97675           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.108214    0.582236           0           0
 goodPosition:   -0.285987   -0.282824        -0.1           1           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   1]

choosing greedy
-59.6865 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   7]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  17]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.36905          -2    -1.07262    -1.07386   -0.998771
  badPosition:      -0.102        -0.1     2.08974           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.108214     1.26996           0           0
 goodPosition:   -0.285987   -0.282824        -0.1        1.91           0           0           0

#########################################################
Episode 6

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.36905          -2    -1.07262    -1.07386   -0.998771
  badPosition:      -0.102        -0.1     2.08974           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.108214     1.26996           0           0
 goodPosition:   -0.285987   -0.282824        -0.1        1.91           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   1]

choosing greedy
-67.5534 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   7]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  17]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.36905          -2    -1.07262    -1.07386    -1.01797
  badPosition:      -0.102        -0.1     2.19708           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.108214       1.787           0           0
 goodPosition:   -0.285987   -0.282824        -0.1      2.7381           0           0           0

#########################################################
Episode 7

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.36905          -2    -1.07262    -1.07386    -1.01797
  badPosition:      -0.102        -0.1     2.19708           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.108214       1.787           0           0
 goodPosition:   -0.285987   -0.282824        -0.1      2.7381           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -8]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -11]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -14]

choosing greedy
-145.586 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -11]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-91.2863 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  -2]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   8]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.03471
  badPosition:      -0.102        -0.1      2.3931           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.108214     2.05651           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     3.49167           0           0           0

#########################################################
Episode 8

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.03471
  badPosition:      -0.102        -0.1      2.3931           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.108214     2.05651           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     3.49167           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

choosing greedy
-156.889 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   1]

choosing greedy
-94.7706 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   4]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.04054
  badPosition:      -0.102        -0.1     2.56184           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.108214     2.27903           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     4.17742           0           0           0

#########################################################
Episode 9

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.04054
  badPosition:      -0.102        -0.1     2.56184           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.108214     2.27903           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     4.17742           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing random
 [state        toFar] [action     fire] [reward  -1] [n_ state        toFar] [t_reward  -3]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.03365
  badPosition:      -0.102        -0.1     2.56184           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     2.37392           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     4.17742           0           0           0

#########################################################
Episode 10

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.03365
  badPosition:      -0.102        -0.1     2.56184           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     2.37392           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     4.17742           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.02845
  badPosition:      -0.102        -0.1     2.56184           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     2.62673           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     4.80145           0           0           0

#########################################################
Episode 11

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.02845
  badPosition:      -0.102        -0.1     2.56184           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     2.62673           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     4.80145           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

choosing greedy
-203.041 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

choosing greedy
102.907 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -2]

choosing greedy
70.3566 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.01802
  badPosition:      -0.102        -0.1     2.72274           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     2.76962           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     5.36932           0           0           0

#########################################################
Episode 12

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.01802
  badPosition:      -0.102        -0.1     2.72274           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     2.76962           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     5.36932           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.01485
  badPosition:      -0.102        -0.1     2.72274           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     2.93356           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     5.88608           0           0           0

#########################################################
Episode 13

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.01485
  badPosition:      -0.102        -0.1     2.72274           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     2.93356           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     5.88608           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -2]

choosing greedy
-44.5215 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward   1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   0]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-146.621 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

choosing greedy
121.894 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386   -0.994683
  badPosition:      -0.102        -0.1      2.8101           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.03145           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     6.35633           0           0           0

#########################################################
Episode 14

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386   -0.994683
  badPosition:      -0.102        -0.1      2.8101           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.03145           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     6.35633           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-74.1969 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   4]

choosing greedy
-57.1959 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  10]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  20]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.00004
  badPosition:      -0.102        -0.1     2.90428           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.13678           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     6.78426           0           0           0

#########################################################
Episode 15

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.00004
  badPosition:      -0.102        -0.1     2.90428           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.13678           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     6.78426           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

choosing greedy
-200.717 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   1]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  11]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386     -1.0193
  badPosition:      -0.102        -0.1     2.94522           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.20687           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     7.17368           0           0           0

#########################################################
Episode 16

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386     -1.0193
  badPosition:      -0.102        -0.1     2.94522           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.20687           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     7.17368           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.01127
  badPosition:      -0.102        -0.1     2.94522           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.27748           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     7.52805           0           0           0

#########################################################
Episode 17

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.01127
  badPosition:      -0.102        -0.1     2.94522           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.27748           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     7.52805           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

choosing greedy
-154.593 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -5]

choosing greedy
107.634 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   1]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  11]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.00239
  badPosition:      -0.102        -0.1      2.9792           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653      3.3265           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     7.85053           0           0           0

#########################################################
Episode 18

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.00239
  badPosition:      -0.102        -0.1      2.9792           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653      3.3265           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     7.85053           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386   -0.999635
  badPosition:      -0.102        -0.1      2.9792           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.37341           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     8.14398           0           0           0

#########################################################
Episode 19

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386   -0.999635
  badPosition:      -0.102        -0.1      2.9792           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.37341           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     8.14398           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386   -0.997466
  badPosition:      -0.102        -0.1      2.9792           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.41131           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     8.41102           0           0           0

#########################################################
Episode 20

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386   -0.997466
  badPosition:      -0.102        -0.1      2.9792           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.41131           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     8.41102           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

choosing greedy
-210.484 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

choosing greedy
146.751 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   1]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  11]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07262    -1.07386    -1.00041
  badPosition:      -0.102        -0.1     3.00811           0           0           0           0
        toFar:   -0.294367    -0.29193        -0.1   -0.173653     3.44797           0           0
 goodPosition:   -0.285987   -0.282824        -0.1     8.65403           0           0           0
