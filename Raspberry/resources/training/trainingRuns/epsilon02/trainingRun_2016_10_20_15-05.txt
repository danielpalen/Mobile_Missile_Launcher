
#########################################################
Episode 1

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:           0           0           0           0           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -11]

choosing greedy
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -31]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 2

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -4]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -11]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -15]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -18]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -19]

choosing greedy
 [state  badPosition] [action     left] [reward  -1] [n_ state     noTarget] [t_reward -20]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -22]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -24]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -25]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -26]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -31]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573      -0.955          -2    -0.54762    -0.54762   -0.534041
  badPosition:    -0.10382           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 3

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573      -0.955          -2    -0.54762    -0.54762   -0.534041
  badPosition:    -0.10382           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -5]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -8]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -16]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -18]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -19]

choosing greedy
 [state  badPosition] [action    right] [reward  -1] [n_ state        toFar] [t_reward -20]

choosing greedy
 [state        toFar] [action     left] [reward  -3] [n_ state  badPosition] [t_reward -23]

choosing greedy
192.913 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -20]

choosing greedy
 [state        toFar] [action    right] [reward  -3] [n_ state  badPosition] [t_reward -23]

choosing greedy
-194.421 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -20]

choosing greedy
37.8401 pixels to the right
 [state        toFar] [action   toward] [reward  -1] [n_ state     noTarget] [t_reward -21]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -22]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -23]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward -24]

choosing greedy
 [state        toFar] [action     fire] [reward  -1] [n_ state        toFar] [t_reward -25]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -0.82143    -0.82143      -0.955          -2   -0.835484   -0.835484   -0.826282
  badPosition:    -0.10382        -0.1        0.57           0           0           0           0
        toFar:        -0.3      -0.297   -0.107438        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 4

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -0.82143    -0.82143      -0.955          -2   -0.835484   -0.835484   -0.826282
  badPosition:    -0.10382        -0.1        0.57           0           0           0           0
        toFar:        -0.3      -0.297   -0.107438        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward -15]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward -12]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -6]

choosing greedy
 [state goodPosition] [action     left] [reward  -3] [n_ state  badPosition] [t_reward  -9]

choosing greedy
344.401 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -6]

choosing greedy
-241.547 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
154.945 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   0]

choosing greedy
 [state goodPosition] [action    right] [reward  -3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
-314.382 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward   0]

choosing greedy
234.706 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   3]

choosing greedy
-120.841 pixels to the left
 [state goodPosition] [action   toward] [reward  -1] [n_ state goodPosition] [t_reward   2]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  12]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475      -0.955          -2    -0.96029    -0.96029   -0.924211
  badPosition:    -0.10382        -0.1     1.58598           0           0           0           0
        toFar:        -0.3      -0.297   -0.107438        -0.1      0.8157           0           0
 goodPosition:     -0.2943   -0.287595        -0.1           1           0           0           0

#########################################################
Episode 5

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475      -0.955          -2    -0.96029    -0.96029   -0.924211
  badPosition:    -0.10382        -0.1     1.58598           0           0           0           0
        toFar:        -0.3      -0.297   -0.107438        -0.1      0.8157           0           0
 goodPosition:     -0.2943   -0.287595        -0.1           1           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -10]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -12]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward -14]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward -11]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -5]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   5]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475     -1.0475    -1.36905          -2    -1.07386    -1.07386   -0.976493
  badPosition:    -0.10382        -0.1     1.58598           0           0           0           0
        toFar:        -0.3      -0.297   -0.107438        -0.1     1.43363           0           0
 goodPosition:     -0.2943   -0.287595        -0.1        1.91           0           0           0


 #########################################################
 Episode 1

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:     -1.0475     -1.0475    -1.36905          -2    -1.07386    -1.07386   -0.976493
   badPosition:    -0.10382        -0.1     1.58598           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     1.43363           0           0
  goodPosition:     -0.2943   -0.287595        -0.1        1.91           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

 choosing greedy
 -76.2892 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

 choosing greedy
 -221.695 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

 choosing greedy
 120.949 pixels to the right
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:     -1.0475     -1.0475    -1.36905          -2    -1.07386    -1.07386   -0.999433
   badPosition:    -0.10382        -0.1      1.9664           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     1.76324           0           0
  goodPosition:     -0.2943   -0.287595        -0.1      2.7381           0           0           0

 #########################################################
 Episode 2

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:     -1.0475     -1.0475    -1.36905          -2    -1.07386    -1.07386   -0.999433
   badPosition:    -0.10382        -0.1      1.9664           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     1.76324           0           0
  goodPosition:     -0.2943   -0.287595        -0.1      2.7381           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
  [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -9]

 choosing greedy
  [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -12]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -14]

 choosing greedy
 -201.855 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -11]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -8]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -5]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   5]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386     -1.0284
   badPosition:    -0.10382        -0.1     2.08739           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     2.04147           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     3.49167           0           0           0

 #########################################################
 Episode 3

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386     -1.0284
   badPosition:    -0.10382        -0.1     2.08739           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     2.04147           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     3.49167           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

 choosing greedy
 -110.001 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -5]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -2]

 choosing greedy
 -85.1672 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   1]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   4]

 choosing greedy
 -49.1936 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   7]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  17]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386    -1.04066
   badPosition:    -0.10382        -0.1     2.40559           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     2.26639           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     4.17742           0           0           0

 #########################################################
 Episode 4

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386    -1.04066
   badPosition:    -0.10382        -0.1     2.40559           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     2.26639           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     4.17742           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -2]

 choosing greedy
 -57.5208 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward   1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   0]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

 choosing greedy
 -167.323 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   4]

 choosing greedy
 -45.5558 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   7]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  17]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386     -1.0233
   badPosition:    -0.10382        -0.1      2.6206           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     2.45149           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     4.80145           0           0           0

 #########################################################
 Episode 5

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386     -1.0233
   badPosition:    -0.10382        -0.1      2.6206           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     2.45149           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     4.80145           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

 choosing greedy
 -109.187 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -5]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   1]

 choosing greedy
 -116.724 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   4]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386    -1.03295
   badPosition:    -0.10382        -0.1     2.76276           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1      2.6046           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     5.36932           0           0           0

 #########################################################
 Episode 6

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386    -1.03295
   badPosition:    -0.10382        -0.1     2.76276           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1      2.6046           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     5.36932           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -5]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386    -1.02572
   badPosition:    -0.10382        -0.1     2.76276           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     2.81058           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     5.88608           0           0           0

 #########################################################
 Episode 7

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386    -1.02572
   badPosition:    -0.10382        -0.1     2.76276           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     2.81058           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     5.88608           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing random
  [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward -10]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -7]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -4]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -1]

 choosing random
 l
  [state goodPosition] [action   search] [reward  -3] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -10]

 choosing greedy
 264.169 pixels to the right
  [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -7]

 choosing greedy
 -146.99 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  -4]

 choosing greedy
 sceneVector discriptor empty

 #########################################################
 Episode 8

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386    -1.02572
   badPosition:    -0.10382        -0.1     2.76276           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     2.81058           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     5.88608           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

 choosing greedy
 -139.655 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -5]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   1]

 choosing greedy
 -95.8364 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   4]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386    -1.03266
   badPosition:    -0.10382        -0.1     2.89199           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     2.90001           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     6.35633           0           0           0

 #########################################################
 Episode 9

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 DeviceNotFoundException: Webcam not found at: 0

 #########################################################
 Episode 10

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386    -1.03266
   badPosition:    -0.10382        -0.1     2.89199           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     2.90001           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     6.35633           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   1]

 choosing greedy
 -76.5097 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward   4]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   2]

 choosing random
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward   1]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   4]

 choosing greedy
 92.1668 pixels to the right
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   7]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  10]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  20]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386    -0.99283
   badPosition:    -0.10382        -0.1     2.93319           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.04013           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     6.78426           0           0           0

 #########################################################
 Episode 11

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386    -0.99283
   badPosition:    -0.10382        -0.1     2.93319           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.04013           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     6.78426           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -5]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386   -0.996599
   badPosition:    -0.10382        -0.1     2.93319           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.14932           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     7.17368           0           0           0

 #########################################################
 Episode 12

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386   -0.996599
   badPosition:    -0.10382        -0.1     2.93319           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.14932           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     7.17368           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -5]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386   -0.997833
   badPosition:    -0.10382        -0.1     2.93319           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.23459           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     7.52805           0           0           0

 #########################################################
 Episode 13

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905          -2    -1.07386    -1.07386   -0.997833
   badPosition:    -0.10382        -0.1     2.93319           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.23459           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     7.52805           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing random
  [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -21]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81008    -1.07386    -1.07386    -1.00803
   badPosition:    -0.10382        -0.1     2.93319           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.23459           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     7.52805           0           0           0

 #########################################################
 Episode 14

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81008    -1.07386    -1.07386    -1.00803
   badPosition:    -0.10382        -0.1     2.93319           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.23459           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     7.52805           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

 choosing greedy
 -165.549 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -5]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   1]

 choosing greedy
 -43.279 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   4]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  14]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81008    -1.07386    -1.07386    -1.02273
   badPosition:    -0.10382        -0.1     3.05028           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.24885           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     7.85053           0           0           0

 #########################################################
 Episode 15

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81008    -1.07386    -1.07386    -1.02273
   badPosition:    -0.10382        -0.1     3.05028           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.24885           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     7.85053           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

 choosing greedy
 r
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

 choosing greedy
 l
  [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

 choosing greedy
 -201.93 pixels to the left
  [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -5]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -2]

 choosing greedy
  [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   1]

 choosing greedy
  [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  11]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81008    -1.07386    -1.07386    -1.02839
   badPosition:    -0.10382        -0.1     3.07774           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.30931           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     8.14398           0           0           0

 #########################################################
 Episode 16

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -3.81008    -1.07386    -1.07386    -1.02839
   badPosition:    -0.10382        -0.1     3.07774           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.30931           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     8.14398           0           0           0
 choosing random
  [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -20]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -5.43936    -1.07386    -1.07386    -1.02839
   badPosition:    -0.10382        -0.1     3.07774           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.30931           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     8.14398           0           0           0

 #########################################################
 Episode 17

 Reading properties.txt file:
 Launcher opened
 VehicleController: Arduino connected!
 starting reinforcement learning

 read qValues from file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -5.43936    -1.07386    -1.07386    -1.02839
   badPosition:    -0.10382        -0.1     3.07774           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.30931           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     8.14398           0           0           0
 choosing greedy
 f
  [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

 choosing random
  [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -21]

 updated qValues written to file: ../resources/training/qValues.txt
   state/action        left       right      toward        fire     forward    backward      search
      noTarget:    -1.25322    -1.25322    -1.36905    -6.90578    -1.07386    -1.07386    -1.03583
   badPosition:    -0.10382        -0.1     3.07774           0           0           0           0
         toFar:        -0.3      -0.297   -0.107438        -0.1     3.30931           0           0
  goodPosition:     -0.2943   -0.287595        -0.1     8.14398           0           0           0
