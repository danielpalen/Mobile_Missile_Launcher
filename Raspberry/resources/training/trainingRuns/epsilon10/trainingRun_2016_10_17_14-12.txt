
#########################################################
Episode 1

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:           0           0           0           0           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -11]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -13]

choosing random
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -33]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:        -0.3        -0.3        -0.5        -0.2           0           0          -2
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 2

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:        -0.3        -0.3        -0.5        -0.2           0           0          -2
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -4]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing random
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -12]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -16]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -17]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state        toFar] [t_reward -19]

choosing greedy
 [state        toFar] [action     left] [reward  -3] [n_ state  badPosition] [t_reward -22]

choosing greedy
 [state  badPosition] [action     left] [reward  -1] [n_ state     noTarget] [t_reward -23]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -25]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -26]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -27]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -32]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:   -0.572738      -0.573      -0.955      -0.542    -0.54762   -0.536932          -2
  badPosition:    -0.10382           0           0           0           0           0           0
        toFar:        -0.3           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 3

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:   -0.572738      -0.573      -0.955      -0.542    -0.54762   -0.536932          -2
  badPosition:    -0.10382           0           0           0           0           0           0
        toFar:        -0.3           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -5]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -10]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -13]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -14]

choosing greedy
 [state  badPosition] [action    right] [reward  -1] [n_ state     noTarget] [t_reward -15]

choosing random
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -18]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -19]

choosing random
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -20]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -22]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -23]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -24]

choosing random
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -44]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.04537    -0.82143      -0.955   -0.829625   -0.835484   -0.781016    -3.80781
  badPosition:    -0.10382   -0.106297           0           0           0           0           0
        toFar:        -0.3           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 4

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.04537    -0.82143      -0.955   -0.829625   -0.835484   -0.781016    -3.80781
  badPosition:    -0.10382   -0.106297           0           0           0           0           0
        toFar:        -0.3           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -5]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -11]

choosing greedy
114.677 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -8]

choosing greedy
 [state        toFar] [action    right] [reward  -3] [n_ state  badPosition] [t_reward -11]

choosing greedy
-96.7779 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -8]

choosing greedy
-33.1111 pixels to the left
 [state        toFar] [action   toward] [reward  -1] [n_ state        toFar] [t_reward  -9]

choosing random
 [state        toFar] [action     left] [reward  -3] [n_ state  badPosition] [t_reward -12]

choosing greedy
125.406 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -9]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state  badPosition] [t_reward -16]

choosing greedy
-264.325 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -13]

choosing random
 [state        toFar] [action    right] [reward  -3] [n_ state  badPosition] [t_reward -16]

choosing greedy
-166.847 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -13]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward -10]

choosing greedy
-72.7315 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -7]

choosing random
 [state  badPosition] [action backward] [reward   0] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -4]

choosing greedy
-49.2316 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   2]

choosing greedy
-118.944 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   5]

choosing greedy
 [state goodPosition] [action     left] [reward  -3] [n_ state  badPosition] [t_reward   2]

choosing greedy
198.732 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   5]

choosing greedy
 [state goodPosition] [action    right] [reward  -3] [n_ state  badPosition] [t_reward   2]

choosing greedy
-170.259 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   5]

choosing greedy
12.2702 pixels to the right
 [state goodPosition] [action   toward] [reward  -1] [n_ state goodPosition] [t_reward   4]

choosing random
f
 [state goodPosition] [action   search] [reward  -3] [n_ state     noTarget] [t_reward   1]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward  -4]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state goodPosition] [t_reward  -6]

choosing greedy
 [state goodPosition] [action  forward] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing random
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -30]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.04537     -1.0475    -1.36905    -1.05142    -1.06426    -1.00061    -5.43704
  badPosition:    -0.10382   -0.106297     1.96213           0  0.00312214           0           0
        toFar:     -0.5643   -0.557062        -0.1     0.85136           0           0           0
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645           0    -0.30955           0

#########################################################
Episode 5

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.04537     -1.0475    -1.36905    -1.05142    -1.06426    -1.00061    -5.43704
  badPosition:    -0.10382   -0.106297     1.96213           0  0.00312214           0           0
        toFar:     -0.5643   -0.557062        -0.1     0.85136           0           0           0
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645           0    -0.30955           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing random
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -3]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing random
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -11]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -14]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -15]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -17]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -18]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -19]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -20]

choosing random
 [state  badPosition] [action     fire] [reward -20] [n_ state  badPosition] [t_reward -40]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -1.36905    -1.15679    -1.16794    -1.03782    -5.43704
  badPosition:    -0.10382   -0.106297     1.96213           0  0.00312214           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     0.85136           0           0           0
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645           0    -0.30955           0

#########################################################
Episode 6

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -1.36905    -1.15679    -1.16794    -1.03782    -5.43704
  badPosition:    -0.10382   -0.106297     1.96213           0  0.00312214           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     0.85136           0           0           0
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645           0    -0.30955           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-178.941 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   4]

choosing greedy
-132.817 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   7]

choosing random
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  10]

choosing greedy
 [state goodPosition] [action backward] [reward  -2] [n_ state        toFar] [t_reward   8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  11]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  21]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -1.36905    -1.15679    -1.16794    -1.03515    -5.43704
  badPosition:    -0.10382   -0.106297     2.17987           0  0.00312214           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     1.61329           0           0           0
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955           1

#########################################################
Episode 7

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -1.36905    -1.15679    -1.16794    -1.03515    -5.43704
  badPosition:    -0.10382   -0.106297     2.17987           0  0.00312214           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     1.61329           0           0           0
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955           1
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing random
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -24]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -1.36905    -1.15679    -1.16794    -1.05902    -6.90393
  badPosition:    -0.10382   -0.106297     2.17987           0  0.00312214           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     1.61329           0           0           0
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955           1

#########################################################
Episode 8

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -1.36905    -1.15679    -1.16794    -1.05902    -6.90393
  badPosition:    -0.10382   -0.106297     2.17987           0  0.00312214           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     1.61329           0           0           0
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955           1
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-136.43 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   4]

choosing greedy
-127.677 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  10]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  20]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -1.36905    -1.15679    -1.16794    -1.04605    -6.90393
  badPosition:    -0.10382   -0.106297     2.36935           0  0.00312214           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.03266           0           0           0
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955        1.91

#########################################################
Episode 9

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -1.36905    -1.15679    -1.16794    -1.04605    -6.90393
  badPosition:    -0.10382   -0.106297     2.36935           0  0.00312214           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.03266           0           0           0
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955        1.91
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -2]

choosing random
 [state  badPosition] [action backward] [reward   0] [n_ state     noTarget] [t_reward  -2]

choosing random
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing random
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -27]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -1.36905    -1.15679    -1.26138    -1.04473    -8.22398
  badPosition:    -0.10382   -0.106297     2.36935           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.03266           0           0           0
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955        1.91

#########################################################
Episode 10

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -1.36905    -1.15679    -1.26138    -1.04473    -8.22398
  badPosition:    -0.10382   -0.106297     2.36935           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.03266           0           0           0
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955        1.91
choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

choosing greedy
159.392 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -2]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -3]

choosing random
 [state        toFar] [action     fire] [reward  -1] [n_ state        toFar] [t_reward  -4]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -1.36905    -1.25156    -1.26138    -1.00382    -8.22398
  badPosition:    -0.10382   -0.106297     2.42215           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.03266           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955        1.91

#########################################################
Episode 11

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -1.36905    -1.25156    -1.26138    -1.00382    -8.22398
  badPosition:    -0.10382   -0.106297     2.42215           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.03266           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955        1.91
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing random
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing random
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -14]

choosing greedy
181.87 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -11]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -5]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   5]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322     -1.7427    -1.25156    -1.26138    -1.03037    -8.22398
  badPosition:    -0.10382   -0.106297     2.50026           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.25385           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955      2.7381

#########################################################
Episode 12

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322     -1.7427    -1.25156    -1.26138    -1.03037    -8.22398
  badPosition:    -0.10382   -0.106297     2.50026           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.25385           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955      2.7381
choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing random
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

choosing greedy
214.097 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -2]

choosing greedy
52.3605 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward   1]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward   0]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   6]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  16]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322     -1.7427    -1.33671    -1.26138   -0.990801    -8.22398
  badPosition:    -0.10382   -0.106297     2.60756           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.44328           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955     3.49167

#########################################################
Episode 13

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322     -1.7427    -1.33671    -1.26138   -0.990801    -8.22398
  badPosition:    -0.10382   -0.106297     2.60756           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.44328           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408    -0.30955     3.49167
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-183.599 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing random
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   4]

choosing greedy
-106.717 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  10]

choosing random
r
 [state goodPosition] [action   search] [reward  -3] [n_ state     noTarget] [t_reward   7]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   6]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward   4]

choosing greedy
-230.748 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   7]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state     noTarget] [t_reward  17]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322     -1.7427    -1.33671    -1.26138   -0.989645    -8.22398
  badPosition:    -0.10382   -0.106297       2.792           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1      2.6729           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408   -0.588592     4.13261

#########################################################
Episode 14

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322     -1.7427    -1.33671    -1.26138   -0.989645    -8.22398
  badPosition:    -0.10382   -0.106297       2.792           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1      2.6729           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408   -0.588592     4.13261
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing random
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward  -9]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -10]

choosing greedy
-79.1782 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-122.051 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   5]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  15]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -2.07871    -1.33671    -1.26138   -0.997114    -8.22398
  badPosition:    -0.10382   -0.106297     2.88345           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.85008           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408   -0.588592     4.76067

#########################################################
Episode 15

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -2.07871    -1.33671    -1.26138   -0.997114    -8.22398
  badPosition:    -0.10382   -0.106297     2.88345           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.85008           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408   -0.588592     4.76067
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing random
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -23]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -2.07871    -1.33671    -1.26138    -1.02521    -9.41183
  badPosition:    -0.10382   -0.106297     2.88345           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.85008           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408   -0.588592     4.76067

#########################################################
Episode 16

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -2.07871    -1.33671    -1.26138    -1.02521    -9.41183
  badPosition:    -0.10382   -0.106297     2.88345           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.85008           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408   -0.588592     4.76067
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -2]

choosing greedy
-167.99 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward   1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   0]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   4]

choosing greedy
-108.979 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  10]

choosing greedy
-117.529 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  13]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  23]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -2.07871    -1.33671    -1.26138   -0.989295    -9.41183
  badPosition:    -0.10382   -0.106297     2.98093           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.96902           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408   -0.588592     5.33221

#########################################################
Episode 17

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -2.07871    -1.33671    -1.26138   -0.989295    -9.41183
  badPosition:    -0.10382   -0.106297     2.98093           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     2.96902           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408   -0.588592     5.33221
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-110.524 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   4]

choosing greedy
-153.826 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  10]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  20]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -2.07871    -1.33671    -1.26138   -0.995009    -9.41183
  badPosition:    -0.10382   -0.106297     3.04159           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1      3.0819           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408   -0.588592     5.85231

#########################################################
Episode 18

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -2.07871    -1.33671    -1.26138   -0.995009    -9.41183
  badPosition:    -0.10382   -0.106297     3.04159           0 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1      3.0819           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532        -0.1   -0.109645   -0.185408   -0.588592     5.85231
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

choosing random
 [state  badPosition] [action  forward] [reward   0] [n_ state  badPosition] [t_reward  -5]

choosing random
-196.191 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing random
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   1]

choosing greedy
-103.549 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   7]

choosing random
-108.597 pixels to the left
 [state goodPosition] [action   toward] [reward  -1] [n_ state goodPosition] [t_reward   6]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  16]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -2.07871    -1.33671    -1.26138   -0.997929    -9.41183
  badPosition:    -0.10382   -0.106297     3.09247   0.0304159 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     3.15248           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532   -0.131477   -0.109645   -0.185408   -0.588592      6.3256

#########################################################
Episode 19

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -2.07871    -1.33671    -1.26138   -0.997929    -9.41183
  badPosition:    -0.10382   -0.106297     3.09247   0.0304159 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     3.15248           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532   -0.131477   -0.109645   -0.185408   -0.588592      6.3256
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-145.189 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   4]

choosing greedy
-113.493 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  10]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  20]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -2.07871    -1.33671    -1.26138   -0.999222    -9.41183
  badPosition:    -0.10382   -0.106297      3.1351   0.0304159 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     3.22798           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532   -0.131477   -0.109645   -0.185408   -0.588592      6.7563

#########################################################
Episode 20

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.25322    -2.07871    -1.33671    -1.26138   -0.999222    -9.41183
  badPosition:    -0.10382   -0.106297      3.1351   0.0304159 -0.00742029           0    -1.98038
        toFar:     -0.5643   -0.557062        -0.1     3.22798           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532   -0.131477   -0.109645   -0.185408   -0.588592      6.7563
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing random
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

choosing greedy
-226.447 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -8]

choosing greedy
-178.316 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -5]

choosing random
 [state        toFar] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -8]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state  badPosition] [t_reward -10]

choosing greedy
49.0071 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -4]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   6]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward     forward    backward      search        fire
     noTarget:    -1.25129    -1.43808    -2.07871    -1.37171    -1.26138   -0.985771    -9.41183
  badPosition:    -0.10382   -0.106297     3.15172   0.0304159 -0.00742029           0    -1.98038
        toFar:   -0.817728   -0.557062        -0.1     3.27274           0           0  -0.0796734
 goodPosition:   -0.282813   -0.281532   -0.131477   -0.109645   -0.185408   -0.588592     7.14823
