
#########################################################
Episode 1

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:           0           0           0           0           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -11]

choosing greedy
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -31]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 2

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:        -0.3        -0.3        -0.5          -2           0           0           0
  badPosition:           0           0           0           0           0           0           0
        toFar:           0           0           0           0           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -4]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -11]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -15]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -18]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -19]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state  badPosition] [t_reward -21]

choosing greedy
 [state  badPosition] [action     left] [reward  -1] [n_ state        toFar] [t_reward -22]

choosing greedy
 [state        toFar] [action     left] [reward  -3] [n_ state  badPosition] [t_reward -25]

choosing random
 [state  badPosition] [action  forward] [reward   0] [n_ state  badPosition] [t_reward -25]

choosing greedy
 [state  badPosition] [action    right] [reward  -1] [n_ state        toFar] [t_reward -26]

choosing greedy
 [state        toFar] [action    right] [reward  -3] [n_ state  badPosition] [t_reward -29]

choosing greedy
-128.035 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -26]

choosing greedy
-32.7733 pixels to the left
 [state        toFar] [action   toward] [reward  -1] [n_ state        toFar] [t_reward -27]

choosing greedy
 [state        toFar] [action     fire] [reward  -1] [n_ state        toFar] [t_reward -28]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573        -0.5          -2     -0.5438      -0.382   -0.417742
  badPosition:        -0.1        -0.1         0.3           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 3

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:      -0.573      -0.573        -0.5          -2     -0.5438      -0.382   -0.417742
  badPosition:        -0.1        -0.1         0.3           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward  -9]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -12]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -14]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -17]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -20]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -21]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -22]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -23]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -25]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -27]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -28]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -29]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -30]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -0.82143    -0.82143      -0.955          -2   -0.832321   -0.835484   -0.814398
  badPosition:        -0.1        -0.1         0.3           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 4

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -0.82143    -0.82143      -0.955          -2   -0.832321   -0.835484   -0.814398
  badPosition:        -0.1        -0.1         0.3           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing random
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing random
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -15]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -16]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -17]

choosing greedy
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward -22]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -24]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -25]

choosing greedy
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -27]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -28]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -29]

choosing random
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -31]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475    -1.04743    -1.36905          -2    -1.07125    -1.17643   -0.995566
  badPosition:        -0.1        -0.1         0.3           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0

#########################################################
Episode 5

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475    -1.04743    -1.36905          -2    -1.07125    -1.17643   -0.995566
  badPosition:        -0.1        -0.1         0.3           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1           0           0           0
 goodPosition:           0           0           0           0           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -5]

choosing greedy
-85.0426 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   4]

choosing greedy
-99.8282 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  10]

choosing greedy
 [state goodPosition] [action     left] [reward  -3] [n_ state goodPosition] [t_reward   7]

choosing greedy
 [state goodPosition] [action    right] [reward  -3] [n_ state goodPosition] [t_reward   4]

choosing greedy
-99.6958 pixels to the left
 [state goodPosition] [action   toward] [reward  -1] [n_ state goodPosition] [t_reward   3]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  13]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475    -1.04743    -1.36905          -2    -1.07125    -1.17643    -1.02569
  badPosition:        -0.1        -0.1    0.818757           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     0.81813           0           0
 goodPosition:        -0.3        -0.3        -0.1           1           0           0           0

#########################################################
Episode 6

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:     -1.0475    -1.04743    -1.36905          -2    -1.07125    -1.17643    -1.02569
  badPosition:        -0.1        -0.1    0.818757           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     0.81813           0           0
 goodPosition:        -0.3        -0.3        -0.1           1           0           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -7]

choosing greedy
 [state     noTarget] [action     left] [reward  -3] [n_ state     noTarget] [t_reward -10]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -11]

choosing greedy
-181.603 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -8]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -5]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -2]

choosing random
-81.7693 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   4]

choosing random
 [state goodPosition] [action  forward] [reward  -1] [n_ state     noTarget] [t_reward   3]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   2]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward   0]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -9]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -15]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -16]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -17]

choosing random
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -37]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25316    -1.36905    -3.81095    -1.26813    -1.17643    -1.09519
  badPosition:        -0.1        -0.1     1.25306           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     1.43545           0           0
 goodPosition:        -0.3        -0.3        -0.1           1   -0.110391           0           0

#########################################################
Episode 7

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25316    -1.36905    -3.81095    -1.26813    -1.17643    -1.09519
  badPosition:        -0.1        -0.1     1.25306           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     1.43545           0           0
 goodPosition:        -0.3        -0.3        -0.1           1   -0.110391           0           0
choosing random
 [state     noTarget] [action   toward] [reward  -5] [n_ state     noTarget] [t_reward  -5]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing random
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward -15]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -16]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -17]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -18]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -19]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -20]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -21]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward -22]

choosing random
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward -19]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward -16]

choosing greedy
-119.688 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward -13]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  -3]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25316     -1.7431    -3.81095    -1.26813    -1.26982    -1.08182
  badPosition:        -0.1        -0.1     1.43775           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     1.75816           0           0
 goodPosition:        -0.3        -0.3        -0.1        1.91   -0.110391           0           0

#########################################################
Episode 8

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25316     -1.7431    -3.81095    -1.26813    -1.26982    -1.08182
  badPosition:        -0.1        -0.1     1.43775           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     1.75816           0           0
 goodPosition:        -0.3        -0.3        -0.1        1.91   -0.110391           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing random
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

choosing greedy
127.609 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -1]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   9]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25316     -1.7431    -3.81095    -1.26813    -1.26982    -1.04832
  badPosition:        -0.1        -0.1     1.58324           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     2.02903           0           0
 goodPosition:        -0.3        -0.3        -0.1      2.7381   -0.110391           0           0

#########################################################
Episode 9

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25316     -1.7431    -3.81095    -1.26813    -1.26982    -1.04832
  badPosition:        -0.1        -0.1     1.58324           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     2.02903           0           0
 goodPosition:        -0.3        -0.3        -0.1      2.7381   -0.110391           0           0
choosing random
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -2]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -12]

choosing greedy
170.286 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -3]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   7]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25316     -1.7431    -3.81095    -1.26813    -1.35332    -1.05998
  badPosition:        -0.1        -0.1     1.74521           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     2.25916           0           0
 goodPosition:        -0.3        -0.3        -0.1     3.49167   -0.110391           0           0

#########################################################
Episode 10

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.25316     -1.7431    -3.81095    -1.26813    -1.35332    -1.05998
  badPosition:        -0.1        -0.1     1.74521           0           0           0           0
        toFar:        -0.3        -0.3        -0.1        -0.1     2.25916           0           0
 goodPosition:        -0.3        -0.3        -0.1     3.49167   -0.110391           0           0
choosing random
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing random
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -11]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -15]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -16]

choosing greedy
-195.62 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -13]

choosing random
 [state        toFar] [action    right] [reward  -3] [n_ state  badPosition] [t_reward -16]

choosing greedy
-202.731 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -13]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward -10]

choosing greedy
-100.002 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -7]

choosing greedy
-41.0957 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state  badPosition] [t_reward  -4]

choosing greedy
-37.4532 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -1]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   2]

choosing greedy
-90.8561 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   5]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  15]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.60539     -1.7431    -3.81095    -1.26813    -1.35332    -1.06286
  badPosition:        -0.1        -0.1     2.44955           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     2.44165           0           0
 goodPosition:        -0.3        -0.3        -0.1     4.17742   -0.110391           0           0

#########################################################
Episode 11

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.60539     -1.7431    -3.81095    -1.26813    -1.35332    -1.06286
  badPosition:        -0.1        -0.1     2.44955           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     2.44165           0           0
 goodPosition:        -0.3        -0.3        -0.1     4.17742   -0.110391           0           0
choosing random
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward  -5]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -7]

choosing greedy
-145.653 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-68.9853 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   2]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   5]

choosing greedy
-110.652 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   8]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  18]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.60539     -1.7431    -3.81095    -1.35206    -1.35332    -1.04573
  badPosition:        -0.1        -0.1     2.68298           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     2.59651           0           0
 goodPosition:        -0.3        -0.3        -0.1     4.80145   -0.110391           0           0

#########################################################
Episode 12

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.60539     -1.7431    -3.81095    -1.35206    -1.35332    -1.04573
  badPosition:        -0.1        -0.1     2.68298           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     2.59651           0           0
 goodPosition:        -0.3        -0.3        -0.1     4.80145   -0.110391           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing random
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing random
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward -14]

choosing random
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -34]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.89077     -1.7431    -5.44066    -1.35206    -1.35332    -1.08037
  badPosition:        -0.1        -0.1     2.68298           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     2.59651           0           0
 goodPosition:        -0.3        -0.3        -0.1     4.80145   -0.110391           0           0

#########################################################
Episode 13

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -1.89077     -1.7431    -5.44066    -1.35206    -1.35332    -1.08037
  badPosition:        -0.1        -0.1     2.68298           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     2.59651           0           0
 goodPosition:        -0.3        -0.3        -0.1     4.80145   -0.110391           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing random
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -7]

choosing greedy
125.87 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing random
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

choosing greedy
-95.9985 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -3]

choosing greedy
-107.942 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   0]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   3]

choosing greedy
-90.3726 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward   6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward   9]

choosing greedy
-101.765 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  12]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  22]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -2.01255     -1.7431    -5.44066    -1.35206    -1.35332    -1.03667
  badPosition:        -0.1        -0.1     2.91896           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     2.78207           0           0
 goodPosition:        -0.3        -0.3        -0.1     5.36932   -0.110391           0           0

#########################################################
Episode 14

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -2.01255     -1.7431    -5.44066    -1.35206    -1.35332    -1.03667
  badPosition:        -0.1        -0.1     2.91896           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     2.78207           0           0
 goodPosition:        -0.3        -0.3        -0.1     5.36932   -0.110391           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing random
 [state     noTarget] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -21]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -2.01255     -1.7431    -6.90703    -1.35206    -1.35332    -1.04337
  badPosition:        -0.1        -0.1     2.91896           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     2.78207           0           0
 goodPosition:        -0.3        -0.3        -0.1     5.36932   -0.110391           0           0

#########################################################
Episode 15

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -2.01255     -1.7431    -6.90703    -1.35206    -1.35332    -1.04337
  badPosition:        -0.1        -0.1     2.91896           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     2.78207           0           0
 goodPosition:        -0.3        -0.3        -0.1     5.36932   -0.110391           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing random
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -5]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -13]

choosing greedy
-74.548 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward -10]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -7]

choosing greedy
-95.622 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -1]

choosing greedy
-112.66 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward   2]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  12]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -2.12185     -1.7431    -6.90703    -1.35206    -1.35332    -1.04472
  badPosition:        -0.1        -0.1     3.04265           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     2.87995           0           0
 goodPosition:        -0.3        -0.3        -0.1     5.88608   -0.110391           0           0

#########################################################
Episode 16

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322    -2.12185     -1.7431    -6.90703    -1.35206    -1.35332    -1.04472
  badPosition:        -0.1        -0.1     3.04265           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     2.87995           0           0
 goodPosition:        -0.3        -0.3        -0.1     5.88608   -0.110391           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing random
 [state     noTarget] [action    right] [reward  -3] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward -12]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -6]

choosing greedy
-121.814 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -3]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   0]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  10]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322     -2.2204     -1.7431    -6.90703    -1.35206    -1.35332     -1.0431
  badPosition:        -0.1        -0.1     3.06798           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     3.02206           0           0
 goodPosition:        -0.3        -0.3        -0.1     6.35633   -0.110391           0           0

#########################################################
Episode 17

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322     -2.2204     -1.7431    -6.90703    -1.35206    -1.35332     -1.0431
  badPosition:        -0.1        -0.1     3.06798           0           0           0           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     3.02206           0           0
 goodPosition:        -0.3        -0.3        -0.1     6.35633   -0.110391           0           0
choosing random
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward  -9]

choosing random
 [state  badPosition] [action backward] [reward   0] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -10]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -11]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -12]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -13]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward -14]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward -15]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward -12]

choosing greedy
-83.1321 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state  badPosition] [t_reward  -6]

choosing greedy
-109.142 pixels to the left
 [state  badPosition] [action   toward] [reward   3] [n_ state goodPosition] [t_reward  -3]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   7]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322     -2.2204     -1.7431    -6.90703    -1.35206    -1.35332    -1.03014
  badPosition:        -0.1        -0.1     3.14608           0           0  -0.0104054           0
        toFar:        -0.3   -0.551067        -0.1        -0.1      3.0764           0           0
 goodPosition:        -0.3        -0.3        -0.1     6.78426   -0.110391           0           0

#########################################################
Episode 18

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322     -2.2204     -1.7431    -6.90703    -1.35206    -1.35332    -1.03014
  badPosition:        -0.1        -0.1     3.14608           0           0  -0.0104054           0
        toFar:        -0.3   -0.551067        -0.1        -0.1      3.0764           0           0
 goodPosition:        -0.3        -0.3        -0.1     6.78426   -0.110391           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing random
 [state     noTarget] [action backward] [reward  -2] [n_ state     noTarget] [t_reward  -8]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing random
 [state     noTarget] [action  forward] [reward  -2] [n_ state     noTarget] [t_reward -11]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -12]

choosing random
 [state  badPosition] [action     fire] [reward -20] [n_ state     noTarget] [t_reward -32]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322     -2.2204     -1.7431    -6.90703    -1.42755    -1.42864    -1.03088
  badPosition:        -0.1        -0.1     3.14608    -2.01031           0  -0.0104054           0
        toFar:        -0.3   -0.551067        -0.1        -0.1      3.0764           0           0
 goodPosition:        -0.3        -0.3        -0.1     6.78426   -0.110391           0           0

#########################################################
Episode 19

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322     -2.2204     -1.7431    -6.90703    -1.42755    -1.42864    -1.03088
  badPosition:        -0.1        -0.1     3.14608    -2.01031           0  -0.0104054           0
        toFar:        -0.3   -0.551067        -0.1        -0.1      3.0764           0           0
 goodPosition:        -0.3        -0.3        -0.1     6.78426   -0.110391           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -9]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state  badPosition] [t_reward -10]

choosing greedy
95.9957 pixels to the right
 [state  badPosition] [action   toward] [reward   3] [n_ state        toFar] [t_reward  -7]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -4]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward  -1]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward   9]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322     -2.2204     -1.7431    -6.90703    -1.42755    -1.42864    -1.03764
  badPosition:        -0.1        -0.1     3.16224    -2.01031           0  -0.0104054           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     3.15741           0           0
 goodPosition:        -0.3        -0.3        -0.1     7.17368   -0.110391           0           0

#########################################################
Episode 20

Reading properties.txt file:
Launcher opened
VehicleController: Arduino connected!
starting reinforcement learning

read qValues from file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322     -2.2204     -1.7431    -6.90703    -1.42755    -1.42864    -1.03764
  badPosition:        -0.1        -0.1     3.16224    -2.01031           0  -0.0104054           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     3.15741           0           0
 goodPosition:        -0.3        -0.3        -0.1     7.17368   -0.110391           0           0
choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -1]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -2]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -3]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -4]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -5]

choosing greedy
r
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -6]

choosing greedy
f
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -7]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state     noTarget] [t_reward  -8]

choosing greedy
l
 [state     noTarget] [action   search] [reward  -1] [n_ state        toFar] [t_reward  -9]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -6]

choosing greedy
 [state        toFar] [action  forward] [reward   3] [n_ state        toFar] [t_reward  -3]

choosing random
 [state        toFar] [action  forward] [reward   3] [n_ state goodPosition] [t_reward   0]

choosing greedy
 [state goodPosition] [action     fire] [reward  10] [n_ state goodPosition] [t_reward  10]

updated qValues written to file: ../resources/training/qValues.txt
  state/action        left       right      toward        fire     forward    backward      search
     noTarget:    -1.25322     -2.2204     -1.7431    -6.90703    -1.42755    -1.42864    -1.03733
  badPosition:        -0.1        -0.1     3.16224    -2.01031           0  -0.0104054           0
        toFar:        -0.3   -0.551067        -0.1        -0.1     3.24062           0           0
 goodPosition:        -0.3        -0.3        -0.1     7.52805   -0.110391           0           0
